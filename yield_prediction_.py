# -*- coding: utf-8 -*-
"""Yield prediction .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g2G48grj1_e2qJVy_jHlPfMhBFU46Rf9
"""
import pickle
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

data=pd.read_csv("yield_df (1).csv")
data

data.drop("Unnamed: 0",axis=1,inplace=True)

data.head()

data.shape

data.size

data.info()

data.describe()

data.nunique()

data['Item'].unique()

data['Area'].unique()

"""**DATA CLEANING**"""

#checking missing values

data.isna().sum()

#checking duplicate values
data.duplicated().sum()

#removing duplicate values
data.drop_duplicates(inplace=True)

data.duplicated().sum()

"""**EDA**"""

data.hist(figsize=(6,10), color="purple",edgecolor="black",linewidth=2)
plt.show()

plt.figure(figsize=(15,15))
sns.countplot(y=data["Area"])
plt.show()

plt.figure(figsize=(6,10))
sns.countplot(data["Item"])
plt.show()

plt.figure(figsize=(7,10))
plt.xticks(rotation=45)
sns.barplot(x=data["Item"],y=data["hg/ha_yield"])
plt.show()

numeric_columns = ['hg/ha_yield', 'average_rain_fall_mm_per_year', 'pesticides_tonnes', 'avg_temp']

plt.figure(figsize=(10, 8))
correlation_matrix = data[numeric_columns].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Heatmap')
plt.show()

sns.pairplot(data[numeric_columns],hue="hg/ha_yield", diag_kind='kde',palette="husl")
plt.show()

"""OUTLIER DETECTION"""

plt.figure(figsize=(15,10))
plt.title("Boxplot")
plt.boxplot(data[['Year', 'hg/ha_yield', 'average_rain_fall_mm_per_year', 'pesticides_tonnes', 'avg_temp']])
plt.show()

"""HANDLING OUTLIERS"""

Q1=data["pesticides_tonnes"].quantile(0.25)
Q3=data["pesticides_tonnes"].quantile(0.75)

IQR=Q3-Q1

low_lim=Q1-1.5*IQR
upp_lim=Q3+1.5*IQR

outlier=[]
for i in data["pesticides_tonnes"]:
     if((i>upp_lim)or(i<low_lim)):
      outlier.append(i)
print("The outlier of pesticides_tonnes is :",outlier)

data["pesticides_tonnes"]=data["pesticides_tonnes"].clip(lower=low_lim,upper=upp_lim)

outlier=[]
for i in data["pesticides_tonnes"]:
     if((i>upp_lim)or(i<low_lim)):
      outlier.append(i)
print("The outlier of pesticides_tonnes is :",outlier)

Q1=data["avg_temp"].quantile(0.25)
Q3=data["avg_temp"].quantile(0.75)

IQR=Q3-Q1

low_lim=Q1-1.5*IQR
upp_lim=Q3+1.5*IQR

outlier=[]
for i in data["avg_temp"]:
     if((i>upp_lim)or(i<low_lim)):
      outlier.append(i)
print("The outlier of avg_temp is :",outlier)

data["avg_temp"]=data["avg_temp"].clip(lower=low_lim,upper=upp_lim)

outlier=[]
for i in data["avg_temp"]:
     if((i>upp_lim)or(i<low_lim)):
      outlier.append(i)
print("The outlier of avg_temp is :",outlier)

plt.figure(figsize=(15,10))
plt.title("Boxplot")
plt.boxplot(data[['Year', 'hg/ha_yield', 'average_rain_fall_mm_per_year', 'pesticides_tonnes', 'avg_temp']])
plt.show()

"""**ENCODING**"""

data.drop("Area",axis=1,inplace=True)

data.head()

from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()

data['Item'] = label_encoder.fit_transform(data['Item'])

data.head()

Item_mapping = {item: index for index, item in enumerate(data['Item'].unique())}

print("Item Mapping:", Item_mapping)

"""**SCALING**"""

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
scaled_data=scaler.fit_transform(data[["Item","Year","average_rain_fall_mm_per_year","pesticides_tonnes","avg_temp"]])
scaled_data

"""**MODEL SELECTION**"""

x=data[['Item','Year','average_rain_fall_mm_per_year','pesticides_tonnes','avg_temp']]
y=data['hg/ha_yield']

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

x_train.shape

y_train.shape

x_test.shape


"""Random forest regressor"""

from sklearn.ensemble import RandomForestRegressor

rf_model = RandomForestRegressor()

rf_model.fit(x_train, y_train)

y_pred_rf = rf_model.predict(x_test)

mae_rf = mean_absolute_error(y_test, y_pred_rf)
mse_rf = mean_squared_error(y_test, y_pred_rf)
r2_rf = r2_score(y_test, y_pred_rf)

print(f"Random Forest Regression: MAE = {mae_rf:.4f}, MSE = {mse_rf:.4f}, RÂ² = {r2_rf:.4f}")


pickle.dump(rf_model, open('model.pkl','wb'))